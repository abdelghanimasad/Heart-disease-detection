# -*- coding: utf-8 -*-
"""heart_disease_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18JIquLkffyCg16FDyS0I8rlgWGNqwgCA

#Heart Disease Detection

Importing Libraries:
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from tensorflow.keras import Sequential
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from sklearn.metrics import make_scorer, accuracy_score
from keras.layers import Dense
from sklearn.model_selection import ParameterGrid

"""Importing Dataset:"""

dataset = pd.read_csv('/content/Ai_project/hungarian_data.csv', header=None)
print(dataset)

"""Cleaning and Processing Data:"""

column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']
dataset.columns = column_names
#replacing unknown values '?' with NULL(NaN) values
dataset.replace('?', pd.NA, inplace=True)
#making all values numeric
dataset = dataset.apply(pd.to_numeric, errors='ignore')
print(dataset)

"""Naive Bayes:"""

#the target
X = dataset.drop('num', axis=1)
#the data
y = dataset['num']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

#insert the mean of all values in the same column into the unknown feild
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

#train the model
model = GaussianNB()
model.fit(X_train_imputed, y_train)

y_pred = model.predict(X_test_imputed)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy}')
print('Classification Report:\n', report)

"""Graph representation (ROC curve):"""

y_probs = model.predict_proba(X_test_imputed)[:, 1]

fpr, tpr, thresholds = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""Neural Network:"""

#the target
X = dataset.drop('num', axis=1)
#the data
y = dataset['num']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

#insert the mean of all values in the same column into the unknown feild
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

y_train = y_train.astype('float32')
y_test = y_test.astype('float32')

#train the model
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train_imputed.shape[1],)),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train_imputed, y_train, epochs=20, batch_size=32, validation_data=(X_test_imputed, y_test))

test_loss, test_accuracy = model.evaluate(X_test_imputed, y_test)
print(f'Test Accuracy: {test_accuracy}')

"""Confusion Matrix:"""

# Making the Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# Plotting the Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", annot_kws={"size": 16})
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""Hyperparameter tuning:"""

param_grid = {
    'optimizer': ['adam', 'sgd'],
    'activation': ['relu', 'sigmoid'],
    'hidden_units': [32, 64, 128],
    'batch_size': [32, 64, 128],
    'epochs': [10, 15, 20]
}

best_accuracy = 0
best_params = None

for params in ParameterGrid(param_grid):
    model = keras.Sequential([
        layers.Dense(64, activation=params['activation'], input_shape=(X_train_imputed.shape[1],)),
        layers.Dense(params['hidden_units'], activation=params['activation']),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=params['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])

    # Train the model
    model.fit(X_train_imputed, y_train, epochs=params['epochs'], batch_size=params['batch_size'], verbose=0)

    # Evaluate the model
    test_loss, test_accuracy = model.evaluate(X_test_imputed, y_test, verbose=0)

    # Check if the current model is the best
    if test_accuracy > best_accuracy:
        best_accuracy = test_accuracy
        best_params = params

# Print the best parameters and accuracy
print("Best parameters found: ", best_params)
print("Best accuracy found: ", best_accuracy)

"""Graph representation (ROC curve):"""

y_probs = model.predict(X_test_imputed).ravel()

fpr, tpr, thresholds = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='red', lw=2, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""Difference in accuracy between Naive Bayes and Neural Network:"""

plt.bar(['Naive Bayes'], [accuracy], color=['blue'])
plt.bar(['Neural Network'], [test_accuracy], color=['green'])

plt.title('Difference in Accuracy')
plt.xlabel('Algorithm')
plt.ylabel('Accuracy')

plt.show()